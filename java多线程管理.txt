java进程线程
    java多线程通用概念
        线程安全问题
            绝对线程安全
            相对线程安全
            线程兼容
            线程对立
        什么是多线程
        什么是程序
        什么是进程
        同步异步
        并行和并发
            并行
            并发
        守护线程
        线程五大状态
            创建
                当用new操作符创建一个线程时
            就绪
                调用start()，处于就绪状态的线程并不一定马上就会执行run()，还需要等待CPU的调度
            运行
                CPU开始调度线程，并开始执行run()
            阻塞
                线程的执行过程中由于一些原因进入阻塞状态，如调用sleep()，尝试取得到一个锁
            死亡
                run()执行完毕或执行过程中遇到一个异常
        状态
            新建
            就绪
                start方法后，进入就绪状态
            运行
                调度到线程开始运行
            阻塞
                等待阻塞，wait
                同步阻塞，synchronized 同步锁获取失败
                sleep,join等阻塞
            死亡
        悲观锁/乐观锁
            悲观锁
                每次操作都会加锁，会造成线程阻塞
            乐观锁
                每次操作不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止，不会造成线程阻塞
        线程的状态迁移
            NEW,RUNNABLE,TERMINATED,WAITING,TIMED_WAITING,BLOCKED
        解决线程协同安全问题
            互斥同步阻塞同步
            非阻塞同步
                乐观并发策略
                不需要的把线程阻塞挂起
                硬件指令集
                    测试并设置
                    获取并增加
                    交换
                    比较并交换CAS
                    加载链接、条件存储
            ThreadLocal线程独享资源
                实现原理
                    private static
                        这种变量在线程的生命周期内起作用，可以减少同一个线程内多个函数或者组件之间一些公共变量传递的复杂度
                    set()
                        1.获取当前线程 2.获取ThreadLocalMap对象 3.校验对象是否为空，不为空set，为空初始化一个map对象
                        ThreadLocalMap
                            当前线程Thread一个叫threadLocals的变量中获取的
                                每个线程Thread都维护了自己的threadLocals变量，所以在每个线程创建ThreadLocal的时候，实际上数据是存在自己线程Thread的threadLocals变量里面的，别人没办法拿到，从而实现了隔离
                            ThreadLocalMap其实就是ThreadLocal的一个静态内部类，每个Thread维护一个ThreadLocalMap映射表，这个映射表的key是ThreadLocal实例本身，value是真正要存储的Object
                            数组，非链表，怎么解决hash冲突？
                            ThreadLocal.ThreadLocalMap是一个比较特殊的Map，它的每个Entry的key都是一个弱引用
                                Entry继承WeakReference
                                这样设计的好处是，如果这个变量不再被其他对象使用时，可以自动回收这个ThreadLocal对象，避免可能的内存泄露
                                ThreadLocal为了避免内存泄露，不仅使用了弱引用维护key，还会在每个操作上检查key是否被回收，进而再回收value
                                    remove()/set()
                                    get()方法总是访问固定几个一直存在的ThreadLocal（如使用线程池，核心线程一直运行的不会被回收）那么清理动作就不会执行，如果你没有机会调用set()和remove()，那么这个内存泄漏依然会发生
                                    当你不需要这个ThreadLocal变量时，主动调用remove()，这样对整个系统是有好处的
                内存泄漏
                InheritableThreadLocal
                    父子类
                    作用？
                        主线程开了一个子线程，希望在子线程中可以访问主线程中的ThreadLocal对象
    应用层
        数据库连接
            ThreadLocal能够实现当前线程的操作都是用同一个Connection，保证了事务！
            Spring采用Threadlocal的方式，来保证单个线程中的数据库操作使用的是同一个数据库连接，同时，采用这种方式可以使业务层使用事务时不需要感知并管理connection对象，通过传播级别，巧妙地管理多个事务配置之间的切换，挂起和恢复
        多线程的使用场景
            验证1万条url路径是否存在
            实现进度条
    使用
        等异步都执行完成之后再执行
    多线程编程
        JUC
            lock
            线程池
                如果使用线程时就去创建一个线程，虽然简单，但是存在很大问题
                    如果并发的线程数量很多，且每个线程都是执行一个时间很短的任务就结束，这样频繁创建线程就会大大降低系统的效率
                线程池通过复用可以大大减少线程频繁创建与销毁带来的性能上的损耗
        并发的问题
            数据竞争
                如果有两个或多个任务在临界段之外对一个共享变量进行写入操作，即没有使用任何同步机制，那么应用程序可能存在数据竞争
                在这些情况下，应用程序的最终结果可能取决于任务的执行顺序
            死锁
                当两个（多个）任务正在等待必须由另一线程释放的某个共享资源，而该线程有正在等待必须由前述任务之一释放的另一个共享资源时，并发应用程序就出现了死锁
                当系统中同时出现以下条件，就会导致死锁，将其称为Coffman条件
                    互斥
                        死锁中涉及的资源必须是不可共享的，一次只有一个任务可以使用该资源
                    占有并等待条件
                        一个任务在占有某一互斥资源时又请求另一互斥资源，当它在等待时，不会释放任何资源
                    不可剥夺
                        资源只能被那些持有它们的任务释放
                    循环等待
                        任务1正等待任务2占有的资源，任务2正在等待任务3占有的资源，依次类推，最终任务n又正在等待任务1所占有的资源，这样就出现了循环等待
                有一些机制可以用来避免死锁
                    忽略
                        最常用的机制，可以假设自己的系统绝不会出现死锁，而如果发生死锁，结果就是停止应用程序且重新执行
                    检测
                        系统中有一项专门分析系统状态的任务，可以检测是否发生了死锁，如果检测到了死锁，可以采取一些措施来修复
                            如，结束某个任务或强制释放某一资源
                    预防
                        如果想防止系统出现死锁，就必须预防Coffman条件中的一条或多条出现
                    规避
                        如果可以在某一任务执行之前得到该任务使用资源的相关信息，则死锁是可以规避的
                        一个任务要开始执行时，可以对系统中空闲的资源和任务所需的资源进行分析，这样就可以判断任务是否能够开始执行
            活锁
                如果系统中两个任务，总是因为对方的行为而改变自己的状态，那么就出现了活锁，最终结果是它们陷入了状态变更的循环而无法继续向下执行
            资源不足
                当某个任务在系统中无法获取其继续执行所需的资源时，就会出现资源不足
                    当有多个任务在等待某一资源且该资源被释放时，系统需要选择下一个可以使用该资源的任务
                    如果系统中没有设计良好的算法，则系统中有些线程很可能要为获取该资源等待很长时间
                解决这一问题就要确保公平原则，所有等待某一个资源的任务必须在某一给定时间之内占有该资源
                    可选方案之一就是实现一个算法，在选择下一个将占有某一资源的任务时，对任务已等待该资源的时间因素加以考虑
                    然而实现锁的公平需要增加额外的开销，这可能会降低程序的吞吐量
            优先权反转
                当一个低优先权的任务持有了一个高优先级任务所需的资源时，就会发生优先权反转
                这样，低优先权的任务就会在高优先权任务之前执行
        并发核心概念：进程间通信
            并发与并行
                定义
                    在单个处理器上采用单核执行多个任务即为并发，这种情况下，操作系统的任务调用程序会很快从一个任务切换到另一个任务，因此看起来所有任务都是同时运行的
                    同一时间内在不同计算机、处理器或处理器核心上同时运行多个任务，即所谓的“并行”
                另外的定义
                    在系统上同时运行多个任务（不同的任务）即并发
                    同时在某个数据集的不同部分上运行同一任务的不同实例即并行
                额外的定义
                    并行即系统同时运行了多个任务
                    并发即一种解释程序员将任务和它们对共享资源的访问同步的不同技术和机制的方法
            同步
                在并发中，可以将同步定义位一种协调两个或更多任务以获得预期结果的机制
                方式
                    控制同步
                        如当一个任务的开始依赖于另一个任务的结束时，第二个任务不能在第一个任务完成之前开始
                    数据访问同步
                        当两个或更多任务访问共享变量时，在任意时间内，只有一个任务可以访问该变量
                临界段
                    一段代码，由于它可以访问共享资源，因此在任何给定时间内，只能被一个任务执行
                    互斥是用来保证这一要求的机制，且可以采用不同的方式来实现
                粒度
                    同步可以帮助在完成并发任务时避免一些错误，但它也为算法引入了一些开销
                    必须仔细地计算任务的数量，这些任务可以独立执行，而无需并行算法中的互通信，这就涉及并发算法的粒度
                    如果算法有粗粒度，同步方面的开销就比较低，反之同步方面的开销就会很高，且该算法的吞吐量可能不会很好
                并发系统中的同步机制
                    信号量 semaphore
                        一种用于控制对一个或多个单位资源进行访问的机制
                        它有一个用于存放可用资源数量的变量，且可以采用两种原子操作来管理该变量
                        互斥是一种特殊类型的信号量，它只能取两个值（资源空闲/资源忙），只有将互斥设置为忙的那个进程才可以释放它
                        互斥可以通过保护临界段来避免出现竞争条件
                    监视器
                        一种在共享资源上实现互斥的机制，它有一个互斥、一个条件变量、两种操作（等待条件/通报条件）
                        一旦通报了该条件，在等待它的任务中只有一个会继续执行
                线程安全
                    如果共享数据的所有用户都受到同步机制的保护，则代码（方法、对象）就是线程安全的
                    数据的非阻塞的CAS原语是不可变的，这样就可以在并发应用程序中使用改代码而不会出任何问题
            不可变对象
                一种特殊的对象，在其初始化后，不能修改其可视状态（其属性值），如果想修改一个不可变对象，则必须创建一个新的对象
                主要优点在于它是线程安全的，可以在并发应用程序使用它而不会出现任何问题
                一个例子就是Java中的String类，当给一个String对象赋新值时，会创建一个新的String对象
            原子操作和原子变量
                与其他任务相比，原子操作是一种发生在瞬间的操作，在并发应用程序中，可以通过一个临界段来实现原子操作，以便对整个操作采用同步机制
                原子变量是一种通过原子操作来设置和获取其值的变量，可以使用某种同步机制来实现一个原子变量，或使用CAS以无锁方式来实现一个原子变量，该方式并不需要任何同步机制
            共享内存与消息传递
                任务可以通过两种不同方式来相互通信
                共享内存
                    通常用于在同一台计算机上运行多任务的情况，任务在读取和写入值时使用相同的内存区域，为了避免出现问题，对该共享内存的访问必须在一个由同步机制保护的临界段内完成
                消息传递
                    通常用于在不同计算机上运行多任务的情形，当一个任务需要与另一个任务通信时，它会发送一个遵循预定义协议的消息
                    如果发送方保持阻塞并等待响应，则该通信是同步的，如果发送方在发送消息后继续执行自己的流程，则该通信是异步的
        线程的生命周期控制
            配置线程的方式
                线程的优先级
                    setPriority
                    getPriority
                getId()
                    该方法返回Thread对象标识符，该标识符是在线程创建时分配的正整数，在线程的整个生命周期中是唯一且无法改变的
                getName()/setName()
                    获取或设置Thread对象的名称，该名称是一个String对象，可以在Thread类的构造函数中建立
                getPriority()/setPriority()
                    可以使用这两种方法来获取或设置Thread对象的优先级
                isDaemon()/setDaemon()
                    允许获取或设置Thread对象的守护条件
                getState()
                    该方法返回Thread对象的状态
            创建线程的方式
                Thread类继承
                Runnable接口
                    创建过程
                        1.创建一个实现了Runnable接口的类
                        2.实现类去实现Runnable中的抽象方法：run()
                        3.创建实现类的对象
                        4.将此对象作为参数传递到Thread类的构造器中，创建Thread类的对象
                            通过Thread类的对象调用start()//调用当前线程的Runnable类型的taraet（MThread）的run（）
                        和Thread方式的区别
                            1. 实现的方式没类的单继承性的局限性
                            ​2. 实现的方式更适合来处理多个线程共享数据的情况。(比如继承Thread中买票例子的变量static,特别是共享数据的时候)
                Callable接口（jdk5.0）
                    创建过程
                        1.创建一个实现Callable的实现类
                        2.实现call方法，将此线程需要执行的操作声明在call()中
                        3.创建Callable接口实现类的对象
                        4.将此Callable接口实现类的对象作为传递到FutureTask构造器中，创建FutureTask的对象
                        5.将FutureTask的对象作为参数传递到Thread类的构造器中，创建Thread对象，并调用start().
                        //获取Callable中call方法的返回值
                                            和Runnable对比
                                                1.call()可以返回值的。
                        2.call()可以抛出异常，被外面的操作捕获，获取异常的信息
                        3.Callable是支持泛型的
                 FutureTask
                匿名类创建
                    new Thread(){重写run方法---共享数据}.start();
                使用线程池创建线程
            结束线程的方式
                stop/destroy
                    线程是一段运行中的代码，一个运行中的方法。运行到一半的线程不能强制杀死
                    如果强制杀死线程，则线程中所使用的资源，如文件描述符、网络连接等无法正常关闭
                    因此，一个线程一旦运行起来，不要强制关闭，合理的做法是让其运行完毕，干净地释放掉所有资源，然后退出
                        如果是一个不断循环运行的线程，就需要用到线程间的通信机制，让主线程通知其退出
                守护线程
                    Java中规定：当所有非守护线程退出后，整个JVM进程就会退出，即守护线程不影响整个JVM进程的退出
                    垃圾回收线程就是守护线程，它们在后台工作，当开发者的所有前台线程都退出后，整个JVM进程就退出了
                设置关闭的标志位
            进程的协作
                线程的暂停/唤醒
                    Thread.sleep()
                    线程的取消
                        Thread.interrupt()
                        interrupt
                            中断目标线程，给目标线程发送一个中断信号，线程被打上中断标记
                        interrupted
                            判断目标线程是否被中断，但是将清除线程的中断标记
                        isInterrupted
                            判断目标线程是否被中断，不会清除中断标记
                        InterruptedException
                            InterruptedException：中断抛出异常
                                抛出场景
                                阻塞类型
                                    轻量级阻塞
                                        能够被中断的阻塞，对应的线程状态是WAITING或TIMED_WAITING
                                    重量级阻塞
                                        synchronized这种不能被中断的阻塞，对应的状态是BLOCKED
                                Thread.interrupted()
                                    精确含义是“唤醒轻量级阻塞”，而不是字面上的“中断一个线程”
                                    它相当于给线程发送了一个唤醒信号，所以如果线程此时恰好处于WAITING/TIMED_WAITING状态，就会抛出一个InterruptedException，且线程被唤醒
                                    如果此时线程没有被阻塞，则线程什么都不会做，但在后续，线程可以判断自己是否收到过其他线程发来的中断信号，然后做一些对应的处理
                            setUncaughtExceptionHandler()
                                当线程执行出现未校验异常时，该方法用于建立未校验异常的控制器
                线程的协作
                    wait
                        wait/notify：唤醒与推迟
                            为什么需要和synchronized一起使用
                                Java中，wait()/notify()是Object的成员函数
                                两个线程之间要通信，对于同一个对象来说，一个线程调用该对象的wait()，另一个对象调用该对象的notify()，该对象本身就需要同步
                                所以，调用wait()、notify()之前，需要先通过synchronized同步给对象，即给该对象加锁
                                synchronized可以加载任何对象的实例方法上，任何对象都可能成为锁，因此，wait()、notify()只能放在Object里面
                            wait()需要释放锁
                                当线程A进入synchronized(obj1)中之后，即对obj1上锁，此时，调用wait()进入阻塞状态；那么，线程B就永远无法进入synchronized(obj1)同步块中，永远无法调用notify()，发生死锁
                                在wait()内部，会先释放锁obj1，然后进入阻塞状态，之后，它被另外一个线程用notify()唤醒，重新获取锁
                                    其次，wait()调用完成后，执行后面的业务逻辑代码，然后退出同步块，再次释放锁
                                如此可避免死锁
                            问题
                                生产者在通知消费者时，也通知了其他生产者，消费者在通知生产者时，也通知了其他消费者
                                原因在于wait()/notify()所作用的对象和synchronized所作用的对象是同一个，只能由一个对象，无法区分队列空和队列满两个条件
                                    这正是Condition要解决的问题
                        notify/notifyAll
                    join()
                        暂停线程的执行，直到调用该方法的线程执行结束为止
                        可以使用该方法等待另一个Thread对象结束
                线程的互斥
                    synchronized方法/代码块
                查看线程
                    currentThread()
        jvm层
            JMM内存模型
                synchronized 锁关键字
                    同步代码块
                    特性
                        可重入
                            检查当前获得锁的线程是不是当前线程，如果是
                        非公平
                        执行结束或者异常自动释放锁
                        互斥
                    修饰对象有
                        一个代码块
                            被修饰的代码块称为同步语句块，作用范围是{}括起来的代码，作用对象是调用这个代码块的对象
                        一个方法
                            被修饰的方法称为同步方法，其作用范围是整个方法，作用的对象是调用这个方法的对象
                        一个静态方法
                            起作用范围是整个静态方法，作用的对象是这个类的所有对象
                        一个类
                            起作用范围是synchronized后面括号括起来的部分，作用主的对象是这个类的对象
                    java锁问题：
                voliate
                CAS
                    基于冲突检测的乐观锁
                    线程自旋
                    带来的问题
                        ABA
                            AtomicStampedReference解决
                        代码块原子性
                        CPU利用率
                    原理
                        Compare And Swap，即比较替换，是实现并发应用到的一种技术
                        操作包含三个操作数：内存位置（V）、预期原值（A）和新值（B）
                        如果内存位置的值与预期原值相匹配，则处理器会自动将该位置值更新为新值，否则，处理器不做任何操作
                        存在问题：ABA问题；循环时间长开销大；只能保证一个共享变量的原子操作
                区别
                    cas与synchronized相比
                        业务长的使用场景区别
                JMM内存模型
                    JMM与happen-before
                        内存可见性问题
                            因为存在CPU缓存一致性协议，多个CPU核心之间缓存不会出现不同步的问题，不会有“内存可见性”问题
                            缓存一致性协议对性能有很大损耗，为了解决这个问题，又进行了各种优化，如Store_buffer、Load_buffer等
                            新加的buffer和CPU一级缓存是异步的，向内存中写入一个变量，这个变量会保存在Store_buffer中，稍后才异步写入L1，同时同步写入主内存
                            多CPU，每个CPU多核，每个核上可能还有多个硬件线程，对于操作系统来说，就相当于一个个逻辑CPU，每个逻辑CPU都有自己的缓存，这些缓存和主内存之间不是完全同步的
                        重排序
                            Store_buffer的延迟写入是重排序的一种，称为内存重排序，除此之外，还有编译器和CPU的指令重排序
                            类型
                                编译器重排序
                                    对于没有先后依赖关系的语句，编译器可以重新调整语句的执行顺序
                                CPU指令重排序
                                    在指令级别，让没有依赖关系的多条指令并行
                                CPU内存重排序
                                    CPU有自己的缓存，指令的执行顺序和写入主内存的顺序不完全一致
                            CPU内存重排序是造成“内存可见性”问题的主因
                        内存屏障
                            为了禁止编译器重排序和CPU重排序，在编译器和CPU层面都有对应的指令，也就是内存屏障（MemoryBarrier），这也正是JMM和happen-before规则的底层实现原理
                            编译器的内存屏障，只是为了告诉编译器不要对指令进行重排序，当编译完成之后，这种内存屏障就消失了，CPU并不会感知到编译器中内存屏障的存在
                            CPU的内存屏障是CPU提供的指令，可以由开发者显式调用
                            内存屏障是很底层的概念，对于开发者来说，一般用volatile就足够了
                            理论层面上，可以把基本的CPU内存屏障分为
                                LoadLoad
                                    禁止读和读的重排序
                                StoreStore
                                    禁止写和写的重排序
                                LoadStore
                                    禁止读和写的重排序
                                StoreLoad
                                    禁止写和读的重排序
                        as-if-serial
                            单线程程序的重排序规则
                                无论什么语言，站在编译器和CPU角度来说，不管怎么重排序，单线程程序的执行结果不能改变
                                即只要操作之间没有数据依赖性，编译器和CPU都可以任意重排序，因为执行结果不会改变，代码看起来就像是完全串行地一行行从头执行到尾，这也就是ai-if-serial语义
                                对于单线程程序来说，编译器和CPU可能做了重排序，但开发者感知不到，也不存在内存可见性问题
                            多线程程序的重排序规则
                                对于多线程，线程之间的数据依赖性太复杂，编译器和CPU没有办法完全理解这种依赖性，并据此做出最合理的优化
                                编译器和CPU只能保证每个线程的as-if-serial语义
                                线程之间的数据依赖和相互影响，需要编译器和CPU的上层来确定
                                上层要告知编译器和CPU在多线程场景下什么时候可以重排序，什么时候不能重排序
                        happen-before
                            说明
                                使用happen-before描述两个操作之间的内存可见性
                                Java内存模型是一套规范，在多线程中
                                    一方面，要让编译器和CPU可以灵活地重排序
                                    另一方面，要对开发者做一些承诺，明确告知开发者不需要感知什么样的重排序，需要感知什么样的重排序
                                    然后根据需要决定这种重排序对程序是否有影响，有则需要开发者显式的通过线程同步机制来禁止重排序
                                如果A_happen-before_B，意味着A的执行结果必须对B可见，即保证跨线程的内存可见性
                                    这不代表A一定在B之前执行，因为对于多线程而言，两个操作的执行顺序是不确定的
                                基于这种描述方法，JMM对开发者做出了一系列承诺
                                    1、单线程中的每个操作，happen-before对应该线程中任意后续操作
                                    2、对volatile变量的写入，happen-before对应后续对这个变量的读取
                                    3、对synchronized的解锁，happen-before对应后续对这个锁的加锁
                            传递性
                                如果A_happen-before_B，B_happen-before_C，则A_happen-before_C
                    volatile关键字
                        64位写入的原子性（Half_Write）
                            因为JVM的规范并没有要求64位的long或double的写入是原子的，在32位机器上，一个64位变量的写入可能被拆分成两个32位的写操作来执行
                            这样，读取的线程就可能读到“一半”的值，解决方法，long前面加上volatile
                        实现原理
                            由于不同的CPU架构的缓存体系不一样，重排序策略不一样，所提供的内存屏障指令也有差异
                            一种参考做法
                                1、在volatile写操作前面插入一个StoreStore屏障，保证volatile写操作不会和之前的写操作重排序
                                2、在volatile写操作后面插入一个StoreLoad屏障，保证volatile写操作不会和之后的读操作重排序
                                3、在volatile读操作后面插入一个LoadLoad+LoadStore屏障，保证volatile读操作不会和之后的读操作、写操作重排序
                        JSR-133
                            从JSR-133内存模型开始（JDK5），仅仅只允许把一个64位long/double的变量的写操作拆分为两个32位的写入来执行，任意的读操作都必须具有原子性（即必须要在单个读事务中执行）
                    final关键字
                        相应的happen-before语义
                            1、对final域的写（构造方法内部），happen-before于后续对final域所在对象的读
                            2、对final域所在对象的读，happen-before于后续对final域的读
            线程阻塞
            上下文切换
            操作系统的线程调度
        并发编程的三要素
            可见性
                当多个线程访问同一个变量时，如果其中一个线程对其做了修改，其他线程能立即获取到最新的指
            原子性
                指一个或多个操作要么全部执行成功要么全部执行失败
            有序性
                程序执行的顺序按照代码的先后顺序执行（处理器可能会对指令进行重排序）