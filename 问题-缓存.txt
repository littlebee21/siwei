数据问题
    应用场景
        支付场景不能用缓存
        适合使用缓存的业务
            基本不变的用户数据，缓存起来
            菜单，商品介绍等基础数据，也可以去使用canal订阅binlog的方式。
            订单，用户数据，不用考虑
        总结：
            我们能放入缓存的数据本就不应该是实时性、一致性要求超高的。
            所以缓存数据的时候加上过期时间，保 证每天拿到当前最新数据即可。
            我们不应该过度设计，增加系统的复杂性
            遇到实时性、一致性要求高的数据，就应该查数据库，即使慢点。
    集群问题
        一致性问题
            集群数据库一致性
            数据库和缓存的一致性
                先写数据库再操作缓存
            缓存数据库一致性
                解决方案
                    将访问操作串行化
                        分布式锁无法保证缓存和数据库的事务问题
                            通过加锁保证并发读写，写写的时候按顺序排好队。读读无所谓。所以适合使用读写锁。（业务不关心 脏数据，允许临时脏数据可忽略）；
                    单一数据源操作
                    设置过期时间
                        缓存数据+过期时间也足够解决大部分业务对于缓存的要求。
                        如果是用户纬度数据（订单数据、用户数据），这种并发几率非常小，不用考虑这个问题，缓存数据加上过期时间，每隔一段时间触发读的主动更新即可
                    延时双删策略：异步
                        通过消息队列的自发自收的方式进行双重删除
                        canal binlog方法
                        通过binlog异步淘汰key
                            普通模式
                            主从模式
                    保障的重试策略
                先缓存再数据库：不太好
                    线程2的情况
                        B读没插入
                            每次读都是老数据
                        B读插入
                            缓存保存B操作后数据，数据库是A操作后数据
                        B写没插入
                            没问题
                        B写插入
                            缓存与数据库数据不一致
                    先删除缓存，再更新数据库
                        旧数据
                            延时双删
                    先更新缓存，再写数据库
                        脏数据
                先数据库再缓存
                    线程2的情况
                    1) 双写模式
                        当数据更新时，更新数据库时同时更新缓存
                        存在问题
                        由于卡顿等原因，导致写缓存2在最前，写缓存1在后面就出现了不一致
                        这是暂时性的脏数据问题，但是在数据稳定，缓存过期以后，又能得到最新的正确数据
                    先更新数据库，再更新缓存cacheaside
                        脏数据
                    2) 失效模式
                        数据库更新时将缓存删除
                                存在问题
                                当两个请求同时修改数据库，一个请求已经更新成功并删除缓存时又有读数据的请求进来，这时候发现缓存中无数据就去数据库中查询并放入缓存，在放入缓存前第二个更新数据库的请求成功，这时候留在缓存中的数据依然是第一次数据更新的数据
                        解决方法
                            1、缓存的所有数据都有过期时间，数据过期下一次查询触发主动更新 
                            2、读写数据的时候(并且写的不频繁)，加上分布式的读写锁。
                    先更新数据库，再删缓存
                        概率很小
            思考模型
                第二个线程的读骚扰
                    读错了
                第二个线程的写骚扰
        释放锁的时许问题
            确保锁的
    缓存
        缓存失效
            缓存穿透了怎么办？
                布隆过滤器
                缓存空的key null
            缓存雪崩了怎么办？
                热点数据永不过期
                过期时间随机
            缓存击穿？
                使用分布式锁
                    规避雪崩
                    热点数据永不过期
                    出现雪崩：熔断降级
                    事前：保证整个redis集群的高可用性，待机快补，合适的内存淘汰策略
                    事中：本地ehcache缓存+hystrix限流
                    事后：使用redis的快照和持久化机制将数据尽快恢复
                热点数据永不过期
                使用集群保证多个相同的key的一致性？
            3.5 缓存热Key
                解决：缓存空对象，布隆过滤器，mvc拦截器
        缓存删除
            3.6 缓存容量内存考虑
                3.6.1 评估容量，合理利用
                3.6.2 Redis的八种内存淘汰机制
                3.6.3 不同的业务场景，Redis选择适合的数据结构
        缓存更新
        热点数据
            01、 MySQL里有2000w数据，Redis中只存20w的数据，如何保证Redis中的数据都是热点数据？
        3.7 Redis一些有坑的命令